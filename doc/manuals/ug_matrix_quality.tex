%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Evaluating matrix quality
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Evaluating the quality of position-specific scoring matrices}

\section{Prerequisite}

This tutorial assumes that you alredy followed the tutorial on \textit{Matrix based pattern matching}.

\section{Why is important to know the quality of a matrix?}

Position-specific scoring matrices are frequently used to predict
transcription factor binding sites in genome sequences.  At this
point, following the tutorial, you have been able to built a matrix
from a set of known binding sites for a transcription factor, and use
it to detect new putative binding sites on different promoters, so the
result is already there. But! What if there was a problem with the
original set of biding sites? Where did they came from? Is the original
experiment 100\% reliable?

Matrices are generally built from a collection of experimentally
characterized binding sites, databases as RegulonDB or TRANSFAC
gather all the information reported in the literature about the
interaction between Transcription Factors and their respective
binding sites, on those databases you can get the sequences to built a
matrix or download one or several available matrices for your
favourite TF.

However, even if you built your own matrix or if you got it from a
database, their reliability to predict novel binding sites is highly
variable, due to the small number of training sites or the
inappropriate choice of parameters when building the matrix.

There are some classical theoretical measures to describe some
properties of matrices, but this measures may fail to predict the
behaviour in real situations, cause they don't tell if the new detected
putative sites might have a biological relevance.

So at the end in order to know if we can trust the sites we detected
with pattern matching methodologies we need to:

\begin{itemize}
\item Know the composition of the matrix.
\item Analyse the sites used to build the matrix.
\item Analyze the behaviour of the matrix in a real situation.
\item Analyze a negative control of the matrix and it's behavior in a
real situation.
\end{itemize}

All this procedure can be done with the program
\textit{matrix-quality} and a correct tune of it's parameters.
This is done combining theoretical and empirical score
distributions to assess the predictive capability of
matrices.

As a example we are going to use the matrix for the \textit{E. coli}
K12 transcriptional factor LexA, which is available at RegulonDB.

{\color{Blue} \begin{footnotesize} 
\begin{verbatim}
AC  ECK12_ECK120012770_LexA.20.cons
XX
ID  ECK12_ECK120012770_LexA.20.cons
XX
P0       A     T     C     G
1       12     3     3     5
2        0     1    22     0
3        0    23     0     0
4        0     0     0    23
5        1    14     2     6
6       12     5     3     3
7        1    15     5     2
8       12     5     2     4
9        6    15     2     0
10      10     6     5     2
11       7    11     5     0
12      13     5     2     3
13       4    12     4     3
14      12     2     7     2
15       0     0    23     0
16      23     0     0     0
17       0     0     0    23
18       1    13     8     1
19      12     6     2     3
20       6    13     2     2
21      11     8     3     1
XX
//
\end{verbatim} \end{footnotesize}
}

Please copy this matrix and paste it on a file. 
For the propose of the chapter the file will be named \textbf{LexA\_matrix.transfac}.  


\section{How to estimate the theoretical distribution of a matrix? }

As has been explained in the previous chapter \textit{matrix-scan}
gives a Weight Score (WS) to each site, and we usually take this weigth or
statistics based on it to decide if the site is good or if it's not.

However, this WS can be misleading, because its range depends on the
matrix width and information content. For example: The relevance of a
site with a WS of 15 detected with a matrix having a WS range of -5 to
40 is not the same as if the range was -5 to 16.

So depending on the WS range you can decide whether a WS for a given
site is relevant. One way to calculate all the possible Weight Scores
that a matrix can give, is to generate an endless random sequence ,
and search for sites with \textit{matrix-scan} but without any
threshold, so it will return ALL the evaluated sites, which means a
lot of sites with negative WS and few ones with positives
WS. This way you'll see not only the highestt and lowest WS, but also
you'll be able to see the frequency of each score.

As a little test we generate a long random sequence based on
\textit{E. coli} K12 genome composition.

{\color{Blue} \begin{footnotesize} 
\begin{verbatim}
random-seq -l 1000 -bg upstream -org Escherichia_coli_K12 -ol 2 \
 -o random_seq_E.coliK12.fas
\end{verbatim} \end{footnotesize}
}

And now we run search sites with our matrix using \textit{matrix-scan}
without any thresholds.

{\color{Blue} \begin{footnotesize}
\begin{verbatim}
matrix-scan -m LexA_matrix.transfac -i random_seq_E.coliK12.fas \
 -bgfile 2nt_upstream-noorf_Escherichia_coli_K12-1str.freq.gz \
 -matrix_format transfac \
 -o LexA_bs_search_random_seq.tab
\end{verbatim} \end{footnotesize} }

So now we can count how many times does a WS appers in a random
enviroment just by chance, remeber the count will change a bit for
each generated random sequence and the variation in the count will decreas as we increase
sequence length.

But instead of doing this manually trying to simulate an infinite
randome sequence and scan it, which will take a lot of time, we will
use \textit{matrix-distrib} and this program will calculate the number
of times a score should appear in an endless random sequence, and
oviusly this result contains as well the range for possible Weight
Scores (WS).

First of all we will need to convert the matrix in to tab format. 

{\color{Blue} \begin{footnotesize} 
\begin{verbatim}
convert-matrix  -i LexA_matrix.transfac \
  -from transfac -to tab \
  -return counts,parameters,consensus 
  -o LexA_matrix.tab
\end{verbatim} \end{footnotesize}}


{\color{Blue} \begin{footnotesize}
\begin{verbatim}
matrix-distrib -m LexA_matrix.tab \
  -bgfile  2nt_upstream-noorf_Escherichia_coli_K12-noov-2str.freq.gz \
  -o LexA_matrix_distrib.tab
\end{verbatim} \end{footnotesize} }

So this simulates a search for sites in an endless random sequence
based on the genome of \textit{E. coli} K12.

In this file you can see the frequency (probability) of finding each
value of WSs, or in other words we have the \textit{ probaility
distribution of weight scores }.
{\color{Blue} \begin{footnotesize}
\begin{verbatim}
XYgraph -i LexA_matrix_distrib.tab -format png \
 -xcol 1 -ycol 2 \
 -o LexA_matrix_probability_distrib.png
\end{verbatim} \end{footnotesize} }

Now we know the range of WS goes from -40 to 17.7, and in the graph
showing the probability distribution of scores you can se the
probability of having a positive score is low, and since the range
goes up to 17 a WS of 15 for a site in the genome, seams to be a good
score, at least in theory.

But this graph is only for one matrix, and is a matrix for one of the
transcriptional factors with the most conserved binding sites, other
matrices based in fewer and/or less conserved sites will have a
different shape, e.g. a widder distribution.

In the output file from \textit{matrix-distrib} we also have the
inverse cumulative distribution of WS at column num. 4 so we can know how frequent
(probable) is to find a WS of a given X value or higher, which is the
definition of the \textbf{P-value}.

{\color{Blue} \begin{footnotesize}
\begin{verbatim}
XYgraph -i LexA_matrix_distrib.tab -format png \
 -xcol 1 -ycol 2,4 \
 -o LexA_matrix_probability_distrib_invcum.png
\end{verbatim} \end{footnotesize} }

But we want to be able to se the probabilities for the higher WSs, for this we will apply log to the y-axis.

{\color{Blue} \begin{footnotesize}
\begin{verbatim}
XYgraph -i LexA_matrix_distrib.tab -format png \
 -xcol 1 -ycol 2,4 -ylog \
 -o LexA_matrix_probability_distrib_invcum_ylog.png
\end{verbatim} \end{footnotesize} }


e.g. As you see in the graph to find a WS of 10 or higher than 10 has
a P-value of aprox. 1x10^{5}\end wwhich seems excellent at first
sight. However, with this cutoff, we would still expect about 42 false
positives if we scan the whole genome of E. coli (4.2Mb) on both
strands.

Remember each matrix has a specific theoretical distribution,
depending on the particular frequency of each residue in each column.

\section{How to compare the theoretical distribution with the scores of the known  binding sites?}


In order to estimate the capability of a matrix to distinguish bona
fide binding sites from genome background, \textit{matrix-quality}
implements a method that relies on the combined analysis of
theoretical and empirical score distributions in positive and negative
control sets.

The sensitivity of a matrix is the fraction of correct sites detected
above a score threshold. 
Sensitivity is defined as
\begin{equation}
Sn = TP /(TP + FN)
\end{equation}	 
where TP is the number true positives (i.e. annotated sites with WS
above a threshold), and FN is the number of false negatives
(i.e. annotated sites scoring below that threshold).

The logic positive control should be the set of sequences that have
been used to build the matri, if we scan this set with the matrix
using \textit{matrix-scan} and calculate the invers cumulative
frequency of scores they should show a high scores distribution.

\textit{matrix-quality} calculates the theoretical score distribution
and also the distribution of scores on diferent set of sequences.

From RegulonDb we download the set of sites used to build the matrix.

{\color{Blue} \begin{footnotesize}
\begin{verbatim}
matrix-quality -v 1 -m LexA_matrix.transfac \
 -seq matrix_sites LexA.fna  \
 -bgfile 2nt_upstream-noorf_Escherichia_coli_K12-ovlp-2str.freq.gz \
 -o matrix-quality_tutorial \
 -matrix_format transfac  

\end{verbatim} \end{footnotesize} }

The blue line in the graphs is the same theoretical distribution we
saw in the previous chapter, now we can look the distribution of
scores for the set of known binding sites, and we can see this
distribution has an important number of positive scores.

However, this matrix is probably over-fitted to these particular
sites, since each of them is in the alignment from which the matrix is
derived. For an unbiased estimate of sensitivity, we would ideally
need two separate collections of sites: one for build-ing the PSSM,
another for testing it. Unfortunately, for most tran-scription
factors, very few binding sites are known. In order to ensure an
independent assessment whilst minimizing the loss of information, the
program matrix-quality performs a Leave-One-Out (LOO) validation,
iteratively discarding one annotated site, re-building the matrix, and
scoring the left-out site with the new matrix. The program also
discards multiple copies of identical sites, which would otherwise
induce the same kind of bias.

The LOO curve provides an unbiased estimate
of the sensitivity of a matrix, and the difference with the matrix
sites curve indicates the level of over-fitting to the
training sites.  




% \p
% \p
% \p


% We propose a method, implemented in the
% program matrix-quality, that c

%  can highlight the enrichment of binding
% sites in sequence sets obtained from high-throughput ChIP-chip
% experi-ments. The method proposed can find many applications for the
% analysis of genomes as well as data coming from recent technolo-gies
% for characterizing gene regulation and transcription factor-DNA
% interactions (expression arrays, ChIP-chip, ChIP-seq, etc).










\textbf{THIS CHAPTER WILL SOON BE WRITTEN BY ALEJANDRA MEDINA RIVERA}
